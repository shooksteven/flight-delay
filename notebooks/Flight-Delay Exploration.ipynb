{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f678869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types \n",
    "\n",
    "# Spark session & context\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc48d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2008|    1|        20|        7|   1706|      1655|   1807|      1758|           OO|     5703| N227SW|               61|            63|     47|       9|      11|   SJC| SBA|     234|     5|      9|        0|            null|       0|        null|        null|    null|         null|             null|\n",
      "|2008|    1|        20|        7|   1811|      1817|   1923|      1929|           OO|     5704| N393SW|               72|            72|     60|      -6|      -6|   SBA| SJC|     234|     4|      8|        0|            null|       0|        null|        null|    null|         null|             null|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: string (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: string (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: string (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: string (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: string (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: string (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: specify the data input directory - this will read all CSV files from this directory\n",
    "flightDF = spark.read.csv(\"original_data/\", header=\"True\", sep=\",\", inferSchema=\"False\", nullValue=\"NA\")\n",
    "flightDF.show(2)\n",
    "flightDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "875d0262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- DayofMonth: string (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: string (nullable = true)\n",
      " |-- ArrDelay: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columnList = [\"Year\", \"Month\", \"DayofMonth\", \"DepTime\", \"UniqueCarrier\", \"FlightNum\", \"ArrDelay\", \"Origin\", \"Dest\"]\n",
    "flightDF = flightDF.select(columnList)\n",
    "flightDF = flightDF.withColumn(\"ArrDelay\", flightDF.ArrDelay.cast(\"int\"))\n",
    "flightDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0cf877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightDF.write.partitionBy(\"Dest\",).parquet(\"wooo.parquet\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12152b4d",
   "metadata": {},
   "source": [
    "Analytics Exploration - usually in a separate project/repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fc13d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is this needed??\n",
    "# parquetDF = spark.read.parquet(\"flights.parquet\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS flights\")\n",
    "spark.sql(\"CREATE TEMPORARY VIEW flights USING parquet OPTIONS (path \\\"flights.parquet\\\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fdbb586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|     avg(ArrDelay)|\n",
      "+------------------+\n",
      "|13.859731660568043|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the average arrdelay of flights landing in LAX\n",
    "spark.sql(\"SELECT AVG(ArrDelay) FROM flights GROUP BY Dest HAVING upper(Dest) LIKE 'LAX'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78efda8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|avg(ArrDelay)|\n",
      "+-------------+\n",
      "|      40.4375|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the average arrdelay of flights where the origin is DEN and the dest is SFO\n",
    "spark.sql(\"SELECT AVG(ArrDelay) FROM flights WHERE upper(Origin) LIKE 'DEN' AND upper(Dest) LIKE 'SFO' LIMIT 20\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9a75c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Dest|\n",
      "+----+\n",
      "| MLB|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine which dest airport had the highest average arrdelay\n",
    "spark.sql(\"SELECT Dest FROM (SELECT Dest, RANK() OVER (ORDER BY AVG(ArrDelay) DESC) AS rank FROM flights GROUP BY Dest) WHERE rank=1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb743939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          AvgDelay|\n",
      "+------------------+\n",
      "|10.353448631124909|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming that we get a new file every hour. Write a script which would run and on hourly basis to calculate and store the average delay data.\n",
    "# Is this meant to be an overall average or a running (hourly) average?\n",
    "avgDelayDF = spark.sql(\"SELECT AVG(ArrDelay) AS AvgDelay FROM flights\")\n",
    "avgDelayDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3715541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightDF.write.partitionBy(\"Dest\",).mode('append').parquet(\"avgFlightDelay.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf71bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
